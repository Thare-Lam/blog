<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Thare</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://thare.cn/"/>
  <updated>2018-10-14T16:25:06.800Z</updated>
  <id>https://thare.cn/</id>
  
  <author>
    <name>Thare_Lam</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用Elasticsearch Scroll实现索引迁移工具</title>
    <link href="https://thare.cn/posts/21fbc3c7.html"/>
    <id>https://thare.cn/posts/21fbc3c7.html</id>
    <published>2018-10-11T08:22:43.000Z</published>
    <updated>2018-10-14T16:25:06.800Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Feb 19 2019 22:30:52 GMT+0800 (China Standard Time) --><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近需要在预发环境测试分词词库，但苦于没有预发环境机器的权限，不能随时改es的配置，也不想麻烦运维。虽然有开发环境的机器权限，但开发环境的索引数据量少，且数据不够优雅，不能很好地反映实际使用效果。所以，需要把预发环境的索引同步到开发环境。安全原因，开发环境和预发环境网络是隔离的，只能通过本地起服务来同步。</p><p>环境信息：</p><ul><li>索引量：100w</li><li>索引大小：1.5G</li><li>ES版本：6.2.3</li></ul><h2 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h2><p>首先考虑的是使用es的scroll API来获取全部数据，<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html" rel="external nofollow noopener noreferrer" target="_blank">官方文档</a>是这样介绍的：</p><blockquote><p>While a <code>search</code> request returns a single “page” of results, the <code>scroll</code> API can be used to retrieve large numbers of results (or even all results) from a single search request, in much the same way as you would use a cursor on a traditional database.</p><p>Scrolling is not intended for real time user requests, but rather for processing large amounts of data, e.g. in order to reindex the contents of one index into a new index with a different configuration.</p></blockquote><p>即scroll可以获取大量结果（search的窗口大小只有10000），甚至是全部。但它不是为了实时请求（准实时）而生，而是为了处理大量的数据，例如为了修改索引配置而重建索引。所以这里使用scroll来迁移索引是再合适不过了。</p><p><strong><em>注意：scroll获取的数据是第一个scroll请求发起时的快照，从那刻以后索引发生的变更都不会影响scroll的结果。也就是说，如果整个scroll过程有1个小时，那么最后获取到的数据是1个小时前的快照。所以，对于有实时性要求的场景需要考虑通过其它手段来保证数据一致性。</em></strong></p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>先看看如何使用scroll。</p><p>首先需要先发一个search请求，并指定scroll值（下面会讲）和其他搜索参数（如size、query等，只需第一次指定，后续请求都会沿用）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">POST /item/_search?scroll=10s</span><br><span class="line">&#123;</span><br><span class="line">    "size": 500,</span><br><span class="line">    "query": &#123;</span><br><span class="line">        "term" : &#123;</span><br><span class="line">            "status" : "1"</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个请求除了返回基本的搜索结果外，还会有一个<code>_scroll_id</code></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"_scroll_id"</span>: <span class="string">"DnF1ZXJ5VGhlbkZldGNoldG56LVJrdUtOVGtHQU1h"</span>,</span><br><span class="line">    <span class="attr">"took"</span>: <span class="number">5</span>,</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个<code>_scroll_id</code>需要传入下次scroll请求中（类似游标），同时也需要指定scroll的值</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">POST  /_search/scroll </span><br><span class="line">&#123;</span><br><span class="line">    "scroll" : "10s", </span><br><span class="line">    "scroll_id" : "JLSGPOTWNTLKNG3SAGLKGKLJ8ASGLKMKSAGLSAMGSNA13KMFGKLNLKASNGCDSD==" </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如此不断请求，直到返回的hits为空，就取到了满足搜索条件的所有数据了。</p><p><strong><em>注意：后续scroll请求不需要指定index。</em></strong></p><p>那么这个scroll参数是什么意思呢？<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html#scroll-search-context" rel="external nofollow noopener noreferrer" target="_blank">官方文档</a>如下</p><blockquote><p>The <code>scroll</code> parameter (passed to the <code>search</code> request and to every <code>scroll</code> request) tells Elasticsearch how long it should keep the search context alive. Its value (e.g. <code>1m</code>, see <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/common-options.html#time-units" rel="external nofollow noopener noreferrer" target="_blank">Time units</a>) does not need to be long enough to process all data — it just needs to be long enough to process the previous batch of results. Each <code>scroll</code> request (with the <code>scroll</code> parameter) sets a new expiry time.</p></blockquote><p>scroll参数用来告诉es需要将搜索上下文保持多久，这个时间<strong>不需要</strong>是你处理全部数据的时间，能保证处理完一批数据就行。例如，某次请求拿到了一批数据，只要在这段时间内处理完这批数据并能发起下一个请求就可以了。</p><p><strong><em>注意：scroll值不是越大越好。因为通常情况下，小的segment会合并成大的segment，同时小的segment会被删除。但在scroll的搜索上下文保持时间段内，小的segment不会被删除，而是被用来返回第一个搜索请求时刻的快照，这样会消耗更多的文件句柄。所以把scroll值设置成稍微比处理数据的时间多几秒就好。</em></strong></p><p>当然，如果不同批次的数据处理没有依赖关系的话，也可以通过多线程来处理数据，这样scroll参数可以设置小一点。</p><p>如果使用过期的_scroll_id将会得到如下报错</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"type"</span>: <span class="string">"search_context_missing_exception"</span>,</span><br><span class="line"><span class="attr">"reason"</span>: <span class="string">"No search context found for id [xxx]"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在scroll请求完后也可以手动清除搜索上下文</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DELETE /_search/scroll</span><br><span class="line">&#123;</span><br><span class="line">    "scroll_id" : [</span><br><span class="line">      "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==",</span><br><span class="line">      "AAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB"</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>清除所有<br></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /_search/scroll/_all</span><br></pre></td></tr></table></figure><p></p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>scroll会用了，那下面就来实现吧。</p><p>基本流程：</p><ol><li>获取需要迁移的索引mapping</li><li>在新的es集群创建索引并设置mapping</li><li>通过scroll不断获取数据并写入新索引，直到scroll获取的数据为空</li></ol><h2 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h2><p><a href="https://github.com/Thare-Lam/elasticsearch-migration" rel="external nofollow noopener noreferrer" target="_blank">elasticsearch-migration</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Feb 19 2019 22:30:52 GMT+0800 (China Standard Time) --&gt;&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h
      
    
    </summary>
    
      <category term="ElasticSearch" scheme="https://thare.cn/categories/ElasticSearch/"/>
    
    
      <category term="ElasticSearch" scheme="https://thare.cn/tags/ElasticSearch/"/>
    
      <category term="索引迁移" scheme="https://thare.cn/tags/%E7%B4%A2%E5%BC%95%E8%BF%81%E7%A7%BB/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch性能调优之设置refresh_interval实战</title>
    <link href="https://thare.cn/posts/c358565.html"/>
    <id>https://thare.cn/posts/c358565.html</id>
    <published>2018-09-28T07:36:51.000Z</published>
    <updated>2018-10-14T16:25:06.799Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Feb 19 2019 22:30:52 GMT+0800 (China Standard Time) --><blockquote><p>接手搜索几个月了，把公司的商品搜索从业务代码剥离成独立应用，再不断调整优化（代码结构），目前暂时趋于稳定（搜索中心化和产品化还有很长一段路要走），也能够迅速响应上层业务方的需求。自己也由一个搜索小白到了小试牛刀的阶段。项目中也还有很多可以改进的地方，自己对ES的深度和广度也有待加强。</p></blockquote><p>先贴上环境信息</p><ul><li>业务背景：商品</li><li>ES版本：6.2.3</li><li>集群配置：5台8核32G SSD</li><li>系统信息：CentOS 7.2 64位</li><li>索引信息：1100w个doc，5个分片，1个副本，约20G（不含副本）</li></ul><p>搜索应用的rt表现如下（qps约20）</p><p><img src="https://coding.net/u/Thare-Lam/p/blog/git/raw/master/asserts/img/0x02/before.jpg" alt="before"></p><p>可以看到，请求主要分布在400ms以内，且有一条明显的100ms分界线。</p><p>之前一直百思不得其解，直到某天看了@跳跳爸的Abc公众号的 <a href="https://mp.weixin.qq.com/s/NngpCYqPeTqXfslWC4opOQ" rel="external nofollow noopener noreferrer" target="_blank">中小规模搜索引擎（ElasticSearch）典型应用场景及性能优化（三）</a>才恍然大悟：</p><blockquote><p>索引配置比较灵活，粒度也比较细，当我们查询索引时其实都是查询某个时间的一个快照数据，只有index searcher重载一次索引文件，这期间（两次reopen index searcher之间）对索引进行的操作才会可见，这段时间也叫做刷新时间（refresh_interval）</p><p>需要注意的是重载索引文件（reopen index searcher）的开销很大，所以一般搜索引擎都是提供近实时的查询服务，以减少重载索引文件的次数，降低系统负载，有个案例：曾经将一个索引的刷新时间从1s调整到5s，整个搜索响应时间从200ms降低到20ms以内，效果可见一斑。</p></blockquote><p><strong><em>高于100ms的请求应该是在es刷新时处理的，所以导致rt高。想象一下，每秒都要对1100w的索引重新刷新，这得多消耗性能。</em></strong></p><p>于是，尝试修改了该索引的refresh_interval为30s（商品搜索实时性没那么高）</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">put /&#123;index&#125;/_settings</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"index"</span>: &#123;</span><br><span class="line">        <span class="attr">"refresh_interval"</span>: <span class="string">"30s"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果十分明显：</p><p><img src="https://coding.net/u/Thare-Lam/p/blog/git/raw/master/asserts/img/0x02/compare.jpg" alt="compare"></p><p>可以看到，在16:05:30时刻将refresh_interval改成了30s，搜索应用的rt瞬间就下降了。并且可以看到，大概每隔30s会出现一两个请求rt较高的情况，这时候就是es重载了索引文件，导致请求变慢。</p><p>这是调整后的日常rt，效果较之前已经好很多了，基本都在100ms以内</p><p><img src="https://coding.net/u/Thare-Lam/p/blog/git/raw/master/asserts/img/0x02/after.jpg" alt="after"></p><p>不过还需继续努力，争取rt在50ms，并想办法消除refresh时的高rt。</p><p>总结一下：</p><ul><li>ES的查询是近实时的（需要做好至少延迟1S的打算），实时性高的场景不适用；</li><li>对于搜索结果实时性不高的场景（如上），可以适当增加refresh_internal，效果真的可见一斑。</li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Feb 19 2019 22:30:52 GMT+0800 (China Standard Time) --&gt;&lt;blockquote&gt;&lt;p&gt;接手搜索几个月了，把公司的商品搜索从业务代码剥离成独立应用，再不断调整优化（代码结构），目前暂时趋于
      
    
    </summary>
    
      <category term="ElasticSearch" scheme="https://thare.cn/categories/ElasticSearch/"/>
    
    
      <category term="ElasticSearch" scheme="https://thare.cn/tags/ElasticSearch/"/>
    
      <category term="性能调优" scheme="https://thare.cn/tags/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"/>
    
  </entry>
  
  <entry>
    <title>Initialization</title>
    <link href="https://thare.cn/posts/8b7d4dee.html"/>
    <id>https://thare.cn/posts/8b7d4dee.html</id>
    <published>2018-09-27T13:07:52.000Z</published>
    <updated>2018-10-14T16:25:06.799Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Feb 19 2019 22:30:52 GMT+0800 (China Standard Time) --><p>果然是懒癌患者，不过应该还没到晚期，还有得治。</p><p>从大学起到研究生再到工作，中间多次下决心坚持写Blog，但最后往往都不了了之，其中最长坚持到一段时间应该是研究生期间了吧（<a href="https://blog.csdn.net/thare_lam" rel="external nofollow noopener noreferrer" target="_blank">献丑了</a>）。</p><p>当然也是知道对自己有帮助的，因为在写的过程中会总结思考，争取把技术和过程尽可能清楚地描述出来，这也是对自己做过和看过的一种总结。常言道，温故而知新。</p><p>所以，今天打算重新拾起，打算利用写Blog这个过程好好总结工作中遇到的问题，并把这些记录下来，给未来的自己留个纪念，同时也希望能够帮助到其他人。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Feb 19 2019 22:30:52 GMT+0800 (China Standard Time) --&gt;&lt;p&gt;果然是懒癌患者，不过应该还没到晚期，还有得治。&lt;/p&gt;&lt;p&gt;从大学起到研究生再到工作，中间多次下决心坚持写Blog，但最后往
      
    
    </summary>
    
      <category term="随笔" scheme="https://thare.cn/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔" scheme="https://thare.cn/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
</feed>
