{"pages":[{"title":"404 Not Found：该页无法显示","date":"2018-10-12T02:05:06.030Z","updated":"2018-10-12T02:05:06.030Z","comments":false,"path":"/404.html","permalink":"https://thare-lam.coding.me/blog//404.html","excerpt":"","text":""},{"title":"关于","date":"2018-10-12T02:05:06.031Z","updated":"2018-10-12T02:05:06.031Z","comments":false,"path":"about/index.html","permalink":"https://thare-lam.coding.me/blog/about/index.html","excerpt":"","text":"教育经历2015.09 - 2018.03 中国科学技术大学软件工程硕士2011.09 - 2015.06 中国计量大学计算机科学与技术学士工作经历2017.12 - 至今 政采云有限公司Java工程师 / 搜索工程师兴趣爱好学习新技术写写代码"},{"title":"分类","date":"2018-10-12T02:05:06.032Z","updated":"2018-10-12T02:05:06.032Z","comments":false,"path":"categories/index.html","permalink":"https://thare-lam.coding.me/blog/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-10-12T02:05:06.033Z","updated":"2018-10-12T02:05:06.033Z","comments":true,"path":"links/index.html","permalink":"https://thare-lam.coding.me/blog/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2018-10-12T02:05:06.033Z","updated":"2018-10-12T02:05:06.033Z","comments":false,"path":"repository/index.html","permalink":"https://thare-lam.coding.me/blog/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-12T02:05:06.033Z","updated":"2018-10-12T02:05:06.033Z","comments":false,"path":"tags/index.html","permalink":"https://thare-lam.coding.me/blog/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"使用Elasticsearch Scroll实现索引迁移工具","slug":"Scroll实现索引迁移工具","date":"2018-10-11T08:22:43.000Z","updated":"2018-10-12T02:06:09.351Z","comments":true,"path":"posts/21fbc3c7.html","link":"","permalink":"https://thare-lam.coding.me/blog/posts/21fbc3c7.html","excerpt":"","text":"背景最近需要在预发环境测试分词词库，但苦于没有预发环境机器的权限，不能随时改es的配置，也不想麻烦运维。虽然有开发环境的机器权限，但开发环境的索引数据量少，且数据不够优雅，不能很好地反映实际使用效果。所以，需要把预发环境的索引同步到开发环境。安全原因，开发环境和预发环境网络是隔离的，只能通过本地起服务来同步。环境信息：索引量：100w索引大小：1.5GES版本：6.2.3文档首先考虑的是使用es的scroll API来获取全部数据，官方文档是这样介绍的：While a search request returns a single “page” of results, the scroll API can be used to retrieve large numbers of results (or even all results) from a single search request, in much the same way as you would use a cursor on a traditional database.Scrolling is not intended for real time user requests, but rather for processing large amounts of data, e.g. in order to reindex the contents of one index into a new index with a different configuration.即scroll可以获取大量结果（search的窗口大小只有10000），甚至是全部。但它不是为了实时请求（准实时）而生，而是为了处理大量的数据，例如为了修改索引配置而重建索引。所以这里使用scroll来迁移索引是再合适不过了。注意：scroll获取的数据是第一个scroll请求发起时的快照，从那刻以后索引发生的变更都不会影响scroll的结果。也就是说，如果整个scroll过程有1个小时，那么最后获取到的数据是1个小时前的快照。所以，对于有实时性要求的场景需要考虑通过其它手段来保证数据一致性。使用先看看如何使用scroll。首先需要先发一个search请求，并指定scroll值（下面会讲）和其他搜索参数（如size、query等，只需第一次指定，后续请求都会沿用）123456789POST /item/_search?scroll=10s&#123; \"size\": 500, \"query\": &#123; \"term\" : &#123; \"status\" : \"1\" &#125; &#125;&#125;这个请求除了返回基本的搜索结果外，还会有一个_scroll_id12345&#123; \"_scroll_id\": \"DnF1ZXJ5VGhlbkZldGNoldG56LVJrdUtOVGtHQU1h\", \"took\": 5, ...&#125;这个_scroll_id需要传入下次scroll请求中（类似游标），同时也需要指定scroll的值12345POST /_search/scroll &#123; \"scroll\" : \"10s\", \"scroll_id\" : \"JLSGPOTWNTLKNG3SAGLKGKLJ8ASGLKMKSAGLSAMGSNA13KMFGKLNLKASNGCDSD==\" &#125;如此不断请求，直到返回的hits为空，就取到了满足搜索条件的所有数据了。注意：后续scroll请求不需要指定index。那么这个scroll参数是什么意思呢？官方文档如下The scroll parameter (passed to the search request and to every scroll request) tells Elasticsearch how long it should keep the search context alive. Its value (e.g. 1m, see Time units) does not need to be long enough to process all data — it just needs to be long enough to process the previous batch of results. Each scroll request (with the scroll parameter) sets a new expiry time.scroll参数用来告诉es需要将搜索上下文保持多久，这个时间不需要是你处理全部数据的时间，能保证处理完一批数据就行。例如，某次请求拿到了一批数据，只要在这段时间内处理完这批数据并能发起下一个请求就可以了。注意：scroll值不是越大越好。因为通常情况下，小的segment会合并成大的segment，同时小的segment会被删除。但在scroll的搜索上下文保持时间段内，小的segment不会被删除，而是被用来返回第一个搜索请求时刻的快照，这样会消耗更多的文件句柄。所以把scroll值设置成稍微比处理数据的时间多几秒就好。当然，如果不同批次的数据处理没有依赖关系的话，也可以通过多线程来处理数据，这样scroll参数可以设置小一点。如果使用过期的_scroll_id将会得到如下报错1234&#123;\"type\": \"search_context_missing_exception\",\"reason\": \"No search context found for id [xxx]\"&#125;在scroll请求完后也可以手动清除搜索上下文1234567DELETE /_search/scroll&#123; \"scroll_id\" : [ \"DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==\", \"AAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB\" ]&#125;清除所有1DELETE /_search/scroll/_all实现scroll会用了，那下面就来实现吧。基本流程：获取需要迁移的索引mapping在新的es集群创建索引并设置mapping通过scroll不断获取数据并写入新索引，直到scroll获取的数据为空项目elasticsearch-migration","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://thare-lam.coding.me/blog/categories/ElasticSearch/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://thare-lam.coding.me/blog/tags/ElasticSearch/"},{"name":"索引迁移","slug":"索引迁移","permalink":"https://thare-lam.coding.me/blog/tags/索引迁移/"}]},{"title":"ElasticSearch性能调优之设置refresh_interval实战","slug":"ElasticSearch性能调优之设置refresh_interval实战","date":"2018-09-28T07:36:51.000Z","updated":"2018-10-12T02:06:09.351Z","comments":true,"path":"posts/c358565.html","link":"","permalink":"https://thare-lam.coding.me/blog/posts/c358565.html","excerpt":"","text":"接手搜索几个月了，把公司的商品搜索从业务代码剥离成独立应用，再不断调整优化（代码结构），目前暂时趋于稳定（搜索中心化和产品化还有很长一段路要走），也能够迅速响应上层业务方的需求。自己也由一个搜索小白到了小试牛刀的阶段。项目中也还有很多可以改进的地方，自己对ES的深度和广度也有待加强。先贴上环境信息业务背景：商品ES版本：6.2.3集群配置：5台8核32G SSD系统信息：CentOS 7.2 64位索引信息：1100w个doc，5个分片，1个副本，约20G（不含副本）搜索应用的rt表现如下（qps约20）可以看到，请求主要分布在400ms以内，且有一条明显的100ms分界线。之前一直百思不得其解，直到某天看了@跳跳爸的Abc公众号的 中小规模搜索引擎（ElasticSearch）典型应用场景及性能优化（三）才恍然大悟：索引配置比较灵活，粒度也比较细，当我们查询索引时其实都是查询某个时间的一个快照数据，只有index searcher重载一次索引文件，这期间（两次reopen index searcher之间）对索引进行的操作才会可见，这段时间也叫做刷新时间（refresh_interval）需要注意的是重载索引文件（reopen index searcher）的开销很大，所以一般搜索引擎都是提供近实时的查询服务，以减少重载索引文件的次数，降低系统负载，有个案例：曾经将一个索引的刷新时间从1s调整到5s，整个搜索响应时间从200ms降低到20ms以内，效果可见一斑。高于100ms的请求应该是在es刷新时处理的，所以导致rt高。想象一下，每秒都要对1100w的索引重新刷新，这得多消耗性能。于是，尝试修改了该索引的refresh_interval为30s（商品搜索实时性没那么高）123456put /&#123;index&#125;/_settings&#123; \"index\": &#123; \"refresh_interval\": \"30s\" &#125;&#125;结果十分明显：可以看到，在16:05:30时刻将refresh_interval改成了30s，搜索应用的rt瞬间就下降了。并且可以看到，大概每隔30s会出现一两个请求rt较高的情况，这时候就是es重载了索引文件，导致请求变慢。这是调整后的日常rt，效果较之前已经好很多了，基本都在100ms以内不过还需继续努力，争取rt在50ms，并想办法消除refresh时的高rt。总结一下：ES的查询是近实时的（需要做好至少延迟1S的打算），实时性高的场景不适用；对于搜索结果实时性不高的场景（如上），可以适当增加refresh_internal，效果真的可见一斑。","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://thare-lam.coding.me/blog/categories/ElasticSearch/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://thare-lam.coding.me/blog/tags/ElasticSearch/"},{"name":"性能调优","slug":"性能调优","permalink":"https://thare-lam.coding.me/blog/tags/性能调优/"}]},{"title":"Initialization","slug":"Initialization","date":"2018-09-27T13:07:52.000Z","updated":"2018-10-12T02:06:09.351Z","comments":true,"path":"posts/8b7d4dee.html","link":"","permalink":"https://thare-lam.coding.me/blog/posts/8b7d4dee.html","excerpt":"","text":"果然是懒癌患者，不过应该还没到晚期，还有得治。从大学起到研究生再到工作，中间多次下决心坚持写Blog，但最后往往都不了了之，其中最长坚持到一段时间应该是研究生期间了吧（献丑了）。当然也是知道对自己有帮助的，因为在写的过程中会总结思考，争取把技术和过程尽可能清楚地描述出来，这也是对自己做过和看过的一种总结。常言道，温故而知新。所以，今天打算重新拾起，打算利用写Blog这个过程好好总结工作中遇到的问题，并把这些记录下来，给未来的自己留个纪念，同时也希望能够帮助到其他人。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://thare-lam.coding.me/blog/categories/随笔/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://thare-lam.coding.me/blog/tags/随笔/"}]}]}