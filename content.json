{"pages":[{"title":"404 Not Found：该页无法显示","date":"2019-03-19T02:07:24.547Z","updated":"2019-02-19T14:48:37.293Z","comments":false,"path":"/404.html","permalink":"https://thare.cn//404.html","excerpt":"","text":""},{"title":"关于","date":"2019-04-01T16:59:00.904Z","updated":"2019-04-01T16:59:00.874Z","comments":false,"path":"about/index.html","permalink":"https://thare.cn/about/index.html","excerpt":"","text":"教育经历2015.09 - 2018.03 中国科学技术大学软件工程（硕士）2011.09 - 2015.06 中国计量大学计算机科学与技术（学士）工作经理2018.03 - 至今 政采云有限公司Java工程师商品搜索（Elasticsearch）兴趣爱好捣鼓新技术看电影自驾强迫症行为"},{"title":"分类","date":"2019-04-01T16:56:52.659Z","updated":"2019-02-19T14:36:42.725Z","comments":false,"path":"categories/index.html","permalink":"https://thare.cn/categories/index.html","excerpt":"","text":""},{"title":"友链","date":"2019-02-19T14:37:42.914Z","updated":"2019-02-19T14:37:42.913Z","comments":true,"path":"links/index.html","permalink":"https://thare.cn/links/index.html","excerpt":"","text":""},{"title":"项目","date":"2019-02-19T14:37:15.887Z","updated":"2019-02-19T14:37:15.886Z","comments":false,"path":"repository/index.html","permalink":"https://thare.cn/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-02-19T14:37:05.939Z","updated":"2019-02-19T14:37:05.938Z","comments":false,"path":"tags/index.html","permalink":"https://thare.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"装修风格设计思想挖掘","slug":"装修风格设计思想挖掘","date":"2019-04-01T16:54:57.000Z","updated":"2019-04-01T16:56:19.872Z","comments":true,"path":"posts/637a7edd.html","link":"","permalink":"https://thare.cn/posts/637a7edd.html","excerpt":"","text":"通过图文向表达自己的设计喜好，便于设计师挖掘。有如下几点原则：个性，令人耳目一新。美观第一，实用第二。简约大方，冷色调，独特又不偏激。设计篇001 床的背景墙、地板002 清爽003 背景墙地板/砖篇考虑如下几种方案（卫生间均地砖）全屋水泥灰地砖全屋木地板（包括厨房）客餐厅厨房地砖，卧室地板001 水泥灰地砖家居篇001 橱柜、移门、地板、橱柜002 电视柜003 电视柜（圣木雅）004 沐浴柜（天工之作）005 橱柜（金牌）006 淋浴房（理想，已预定）门篇001 TATA木门（已预定）###","categories":[{"name":"随笔","slug":"随笔","permalink":"https://thare.cn/categories/随笔/"}],"tags":[{"name":"装修","slug":"装修","permalink":"https://thare.cn/tags/装修/"}]},{"title":"商品ES索引同步历程","slug":"商品ES索引同步历程","date":"2019-03-29T16:58:57.000Z","updated":"2019-03-29T17:10:25.743Z","comments":true,"path":"posts/23fc8314.html","link":"","permalink":"https://thare.cn/posts/23fc8314.html","excerpt":"","text":"前言最近对商品es同步应用（item-dump）做了些优化，感觉已经到了比较稳定成熟的阶段（啪啪），决定对整个商品es同步方案历程做个总结，希望能对其它同学在做es同步上提供参考。商品索引在我们公司应该算是最复杂的索引，非常具有代表性：数据量大（目前2500w+，日增商品数高达10w）实时性要求高（使用es搜索取代了一些慢sql，相当于把es当db来用）业务场景复杂，目前共有5套商品索引需要聚合非常多的业务信息，且聚合过程中需要做一些逻辑处理更新频率高下面会通过几个方面来讲讲我在商品es同步中做的一些改进。欢迎提出宝贵（吐）建（槽）议。应用独立性非独立最开始商品es同步的代码是与商品业务代码存在于同一项目，部署在同一jvm中。在初期这种方案可以节约开发时间和精力，但会带来以下问题：与业务相互影响影响业务：es同步需要长时间调用大量接口且占用CPU从而影响正常业务请求。被业务影响：业务原因造成宕机导致同步失败。发版不独立。es同步代码和部分业务代码分属不同团队，项目发版需要协调几个团队。且如果一方的代码需要回滚，又要做分支的处理重新发版，非常痛苦。独立与业务应用独立，互不影响。全量同步当在一个新环境部署时，需要先执行全量同步。单机任务在一个JVM中获取全量的商品信息并同步至es中。这种方案有如下缺点：不能利用集群优势加快任务处理速度。不支持恢复。如果在任务执行过程中应用宕机，那么整个任务都要重新开始。如果要停止任务，需要重启应用。MQ分布式任务将商品id发送到mq中，消费者消费消息即可。这种方案有如下优点：利用集群优势分布式处理，降低任务总耗时。可以通过调整mq消费者线程数来调整任务的处理速度。支持恢复。当应用在全量同步任务过程中发生宕机，重启后继续消费消息即可。停止同步任务只需重置mq消费位点。商品ID获取全量同步方法的入参是商品id，因此需要获取到所有的商品id。遍历商品表遍历商品表获取到所有的商品id，这种方法比较耗时（遍历全表）。且如果在中途查询db失败，那么需要重新开始获取所有id。取id从1取至max由于商品表id是连续递增的，可以先获取到maxId，然后从1到maxId遍历发送消息。这样几秒钟就能发送完所有消息，同时又能减少db查询。使用redis存储id商品表接入drds（分库分表）后，商品id不再是连续递增的，中间会存在很大的间隔。这种情况下，再通过从1到maxId遍历发送消息会导致消费方接收到很多不存在的id，从而造成很多的无用接口调用。使用redis存储商品id：冷启动需要初始化，遍历所有表获取全量的商品id（只需执行一次）对商品表做canal监听，有新商品产生则把id存入redis商品drds是通过id做路由的，通过ids查询时如果ids存在于不同表实例中，会对不同表做查询最后再汇总。为了节约汇总耗时，同时降低不必要的db性能损耗，我们对不同商品表实例做了redis的key区分（canal可以拿到表实例），这样在做dump时依次取不同实例的id，批量查询商品时就能保证db查询只会查询一个表实例。热数据实时同步当数据库中数据发生变更时，需要同步最新数据至es。可以通过canal监听表变更（Insert、Update、Delete）对文档做更新。同步所有初期考虑实现简单，当监听的表发生变更时，根据变更的数据取到对应的商品id（如商品表变更取id，服务商品表变更取该服务商品对应的商品id），然后调用同步方法（代码复用，全量同步时使用的方法）。这种方法也是简单粗暴，不易出错，但有如下问题：有些不必要更新的信息也通过RPC调用去获取了，产生了不必要的调用，且增加了增量更新的耗时，从而降低了索引数据的实时性。当表变更数据量大时，由于RPC的调用耗时，更容易产生消息堆积，从而进一步降低了索引的实时性，且会增加调用的接口应用的压力。当与商品表有一对多关系的数据发生更新时，那么需要对该数据关联的多个商品做同步，这种数据就很难做到实时更新。如：假设一个协议下有m个商品，同步一个商品需要调用n个RPC接口组装数据，那么当这个协议信息发生变更时，需要调用m*n次RPC接口组装数据；而一个协议下可能有高达几万的商品，通过这种方式去实时更新商品的协议信息几乎不可能（单条消息消费时间长）。按需同步对于变更的数据，其实只需要同步es中的部分数据即可。如上所举例子，某个协议发生了变更，只需要更新该协议下商品索引中的的协议信息，使用es的updateByQuery即可（类似sql的update语句：update items set protocol_info = x where protocol_id = y）。这种方案有如下优点：canal消息中可以拿到更新的字段，对于es中不关心的字段的变更可以不做处理。由于canal消息中可以拿到更新后的字段，在更新es时不需要再通过RPC调用去获取数据（某些场景下还是需要通过rpc调用获取数据）。但这种方案也有一些缺点：代码编写时需要关心es中的字段和数据库的字段关系。新增字段需要更改增量更新的代码，开发过程中可能疏漏造成某些字段更新不及时。冷数据同步商品索引中存在一些实时性不高（接受T+1的延迟）的信息。如：采购目录、仓库、配送地等。这类信息需要在每天非业务时间（00:00 ~ 07:00）同步一遍（同步需要调用大量rpc接口，为了不影响正常业务，需要在非业务时间段执行）。同步所有信息每天进行一次全量同步，组装所有数据更新至索引。这种方式简单粗暴，且能够为增量同步做兜底（某些异常情况下增量同步可能会失败）。但同时也带来其它问题：全量同步需要大量调用接口，导致应用和数据库在全量同步期间相关接口qps飙升、db实例cpu使用率飙升（使用率存在峰值，需要消峰），存在隐患。索引数和商品数量不断增长，已经不能保证在非业务时间内对所有索引做完一次全量同步。每日依赖一个如此重的任务让人感觉非常不踏实。只同步冷数据只针对冷数据做同步，有如下优点：大大减少rpc接口调用，缓解了应用和db的压力，降低风险。但这种方案不能为增量同步做兜底了。因此需要保证热数据实时同步能够稳定。为了保证热数据能够实时同步稳定，我们做了以下处理：同步失败告警通知。若同步失败，第一时间通知到相关人员进行处理（关键字告警）。同步失败重试。若同步失败，对失败的消息进行重试。大部分情况下（目前没有遇到其它情况），同步失败往往是某些应用突然宕机，但都能在可接受时间内恢复。恢复成功后消息重试即可。只同步有更新的冷数据（todo，感谢 @白杨 提供方案）也不是所有的冷数据需要同步。一般情况下，冷数据更新频率比较低，可以考虑只针对当日更新的冷数据做更新（假定目前的数据是最新）。具体方案如下：记录冷数据表当日更新记录（可以使用canal监听，使用redis记录）根据更新记录，从es中搜索出需要更新的文档，只更新这些文档对应的冷数据例如，采购目录更新频率很低，商品通过区划和类目获取采购目录。当采购目录发生变更时，记录对应的区划和类目。更新采购目录时，通过发生了变更的区划和类目搜索出对应的商品，再对这些商品做更新即可。目前每天需要更新600w+商品的采购目录信息，使用这种方案可以大大减少接口调用。Canal消费者隔离所有canal消息均发向同一topic，根据tag区分（库名+表名，db_name.table_name）。共用消费者一个索引关心的多张表使用同一个消费者（订阅多个tag），消费者通过tag来区分表做不同操作。这种做法会可能会造成实时性要求不那么高的数据更新阻塞了实时性要求高的数据更新。如：一个商品索引的增量更新同时订阅了商品表和服务商品表（使用同一个消费者，商品信息的实时性高于服务商品信息）。当服务商品表发生大量插入时（供应商批量设置服务商品，最多高达10w+），会导致消息堆积。此时若商品表发生变更，商品信息的更新会滞后。隔离消费者根据场景使用不同消费者消费不同表的canal消息，不同表消息互不影响。同时，可以根据不同数据的实时性要求对不同消费者设置不同线程数，增加灵活性。任务类型Spring Scheduled Job直接在方法上添加@Scheduled注解即可设置定时任务。这种方案实现简单，但不能随时调整触发时间，也不支持主动触发和关闭。Elastic Job通过elastic job控制台可以很方便地调整触发时间，也能主动触发和关闭。To be continuedSee you later…","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://thare.cn/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://thare.cn/tags/Elasticsearch/"}]},{"title":"Elasticsearch DSL快速上手指南","slug":"Elasticsearch DSL快速上手指南","date":"2019-03-22T14:07:47.000Z","updated":"2019-03-29T17:06:03.545Z","comments":true,"path":"posts/41633c75.html","link":"","permalink":"https://thare.cn/posts/41633c75.html","excerpt":"","text":"本文整理常用的Elasticsearch dsl，旨在帮助初学者能够快速构造dsl。如果想精通，还是阅读官方文档为佳。如何搜索向ES发送rest请求即可1$ curl -XPOST http://ip:port?indexName/_search -d \"json格式的dsl\"搜索先介绍几种复合查询类型（需要包在bool中使用，详情看下方例子） 官网传送门类型说明must必须满足。包含在must内的条件都必须要满足，且会影响最后搜索得分。must_not必须不满足。包含在must_not内的条件都不应该满足，不会影响最后搜索得分。filter过滤。和must很像，但有两个区别1. 不会影响搜索得分，速度较must更快2.在ES内会有缓存，加快下次同样条件的查询should在should内的条件之间是或关系。再介绍几种常用的搜索类型 官网传送门类型说明term类似sql中的=terms类似sql中的inmatch分词匹配，一般嵌套在must内使用。字段类型为textmatch_phrase短语匹配，一般嵌套在must内使用。range范围匹配exists存在wildcard模糊查询（禁止在程序中使用）下面通过一段dsl来理解12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#123; \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"match\": &#123; \"name\": \"手机\" &#125; &#125; ], \"must_not\": [ &#123; \"term\": &#123; \"status\": -3 &#125; &#125;, &#123; \"term\": &#123; \"level\": 1 &#125; &#125; ], \"filter\": [ &#123; \"range\": &#123; \"price\": &#123; \"from\": 100, //下边界为100 \"to\": null, // 无上边界 \"include_lower\": true, // 包含下边界 \"include_upper\": false // 包含上边界 &#125; &#125; &#125; ], \"should\": [ &#123; \"term\": &#123; \"brandId\": 1 &#125; &#125;, &#123; \"term\": &#123; \"brandId\": 2 &#125; &#125; ] &#125; &#125;&#125;这段dsl的含义是name能匹配上”手机”status不为-3且level不为1价格大于等于100brandId没有限制。很奇怪对不对？看看官方解释If the bool query is in a query context and has a must or filter clause then a document will match the bool query even if none of the should queries match. In this case these clauses are only used to influence the score.意思是：如果一个should同时和must或filter存在同一级，则搜索出来的文档可以不满足should中的条件，should中的条件仅仅会影响搜索得分。因此，在这种情况下，brandId为1或2的结果搜索得分会更高。如果想达到或关系要怎么做呢？有两种办法：同级查询类型中没有must或filter将should包在filter内，例12345678910111213141516171819202122&#123; ... \"filter\":[ &#123; \"bool\":&#123; // 记得包在bool中 \"should\":[ &#123; \"term\": &#123; \"brandId\": 1 &#125; &#125;, &#123; \"term\": &#123; \"brandId\": 2 &#125; &#125; ] &#125; &#125; ] ...&#125;搜索属性几种常用搜索属性 官网传送门类型说明from从第几条结果开始size返回多少条结果_source控制返回的字段sort排序方式，默认按搜索得分倒序排序看个例子1234567891011121314151617&#123; \"from\": 10, \"size\": 20, \"_source\": [\"id\", \"name\"], \"sort\":[ &#123; \"updatedAt\": &#123; \"order\": \"desc\" &#125; &#125;, &#123; \"id\": &#123; \"order\": \"asc\" &#125; &#125; ]&#125;表示从第10条记录开始，返回20条记录只返回id和name两个字段先按更新时间倒序，再按id升序排序聚合几种常用聚合类型 官网传送门类型说明terms类似group bycardinality类似count(distinct)extended_stats计算count、sum、min、max等看个例子12345678910111213141516171819&#123; \"aggs\":&#123; //也可写为aggregations \"agg1\":&#123; \"terms\":&#123; \"field\": \"shopId\" &#125; &#125;, \"agg2\":&#123; \"cardinality\":&#123; \"field\": \"status\" &#125; &#125;, \"agg3\":&#123; \"extended_stats\":&#123; \"field\": \"price\" &#125; &#125; &#125;&#125;这些聚合的含义是agg1：对shopId做group byagg2：统计共有多少种statusagg3：查看价格的多种统计结果最后看个比较完整的dsl123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&#123; \"from\": 10, \"size\": 20, \"_source\": [ \"id\", \"name\" ], \"sort\": [ &#123; \"updatedAt\": &#123; \"order\": \"desc\" &#125; &#125;, &#123; \"id\": &#123; \"order\": \"asc\" &#125; &#125; ], \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"match\": &#123; \"name\": \"手机\" &#125; &#125; ], \"must_not\": [ &#123; \"term\": &#123; \"status\": -3 &#125; &#125;, &#123; \"term\": &#123; \"level\": 1 &#125; &#125; ], \"filter\": [ &#123; \"range\": &#123; \"price\": &#123; \"from\": 100, \"to\": null, \"include_lower\": true, \"include_upper\": false &#125; &#125; &#125; ], \"should\": [ &#123; \"term\": &#123; \"brandId\": 1 &#125; &#125;, &#123; \"term\": &#123; \"brandId\": 2 &#125; &#125; ] &#125; &#125;, \"aggs\": &#123; \"agg1\": &#123; \"terms\": &#123; \"field\": \"shopId\" &#125; &#125;, \"agg2\": &#123; \"cardinality\": &#123; \"field\": \"status\" &#125; &#125;, \"agg3\": &#123; \"extended_stats\": &#123; \"field\": \"price\" &#125; &#125; &#125;&#125;","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://thare.cn/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://thare.cn/tags/Elasticsearch/"}]},{"title":"使用Elasticsearch Scroll实现索引迁移工具","slug":"Scroll实现索引迁移工具","date":"2018-10-11T08:22:43.000Z","updated":"2019-03-22T14:10:12.223Z","comments":true,"path":"posts/21fbc3c7.html","link":"","permalink":"https://thare.cn/posts/21fbc3c7.html","excerpt":"","text":"背景最近需要在预发环境测试分词词库，但苦于没有预发环境机器的权限，不能随时改es的配置，也不想麻烦运维。虽然有开发环境的机器权限，但开发环境的索引数据量少，且数据不够优雅，不能很好地反映实际使用效果。所以，需要把预发环境的索引同步到开发环境。安全原因，开发环境和预发环境网络是隔离的，只能通过本地起服务来同步。环境信息：索引量：100w索引大小：1.5GES版本：6.2.3文档首先考虑的是使用es的scroll API来获取全部数据，官方文档是这样介绍的：While a search request returns a single “page” of results, the scroll API can be used to retrieve large numbers of results (or even all results) from a single search request, in much the same way as you would use a cursor on a traditional database.Scrolling is not intended for real time user requests, but rather for processing large amounts of data, e.g. in order to reindex the contents of one index into a new index with a different configuration.即scroll可以获取大量结果（search的窗口大小只有10000），甚至是全部。但它不是为了实时请求（准实时）而生，而是为了处理大量的数据，例如为了修改索引配置而重建索引。所以这里使用scroll来迁移索引是再合适不过了。注意：scroll获取的数据是第一个scroll请求发起时的快照，从那刻以后索引发生的变更都不会影响scroll的结果。也就是说，如果整个scroll过程有1个小时，那么最后获取到的数据是1个小时前的快照。所以，对于有实时性要求的场景需要考虑通过其它手段来保证数据一致性。使用先看看如何使用scroll。首先需要先发一个search请求，并指定scroll值（下面会讲）和其他搜索参数（如size、query等，只需第一次指定，后续请求都会沿用）123456789POST /item/_search?scroll=10s&#123; \"size\": 500, \"query\": &#123; \"term\" : &#123; \"status\" : \"1\" &#125; &#125;&#125;这个请求除了返回基本的搜索结果外，还会有一个_scroll_id12345&#123; \"_scroll_id\": \"DnF1ZXJ5VGhlbkZldGNoldG56LVJrdUtOVGtHQU1h\", \"took\": 5, ...&#125;这个_scroll_id需要传入下次scroll请求中（类似游标），同时也需要指定scroll的值12345POST /_search/scroll &#123; \"scroll\" : \"10s\", \"scroll_id\" : \"JLSGPOTWNTLKNG3SAGLKGKLJ8ASGLKMKSAGLSAMGSNA13KMFGKLNLKASNGCDSD==\" &#125;如此不断请求，直到返回的hits为空，就取到了满足搜索条件的所有数据了。注意：后续scroll请求不需要指定index。那么这个scroll参数是什么意思呢？官方文档如下The scroll parameter (passed to the search request and to every scroll request) tells Elasticsearch how long it should keep the search context alive. Its value (e.g. 1m, see Time units) does not need to be long enough to process all data — it just needs to be long enough to process the previous batch of results. Each scroll request (with the scroll parameter) sets a new expiry time.scroll参数用来告诉es需要将搜索上下文保持多久，这个时间不需要是你处理全部数据的时间，能保证处理完一批数据就行。例如，某次请求拿到了一批数据，只要在这段时间内处理完这批数据并能发起下一个请求就可以了。注意：scroll值不是越大越好。因为通常情况下，小的segment会合并成大的segment，同时小的segment会被删除。但在scroll的搜索上下文保持时间段内，小的segment不会被删除，而是被用来返回第一个搜索请求时刻的快照，这样会消耗更多的文件句柄。所以把scroll值设置成稍微比处理数据的时间多几秒就好。当然，如果不同批次的数据处理没有依赖关系的话，也可以通过多线程来处理数据，这样scroll参数可以设置小一点。如果使用过期的_scroll_id将会得到如下报错1234&#123;\"type\": \"search_context_missing_exception\",\"reason\": \"No search context found for id [xxx]\"&#125;在scroll请求完后也可以手动清除搜索上下文1234567DELETE /_search/scroll&#123; \"scroll_id\" : [ \"DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==\", \"AAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB\" ]&#125;清除所有1DELETE /_search/scroll/_all实现scroll会用了，那下面就来实现吧。基本流程：获取需要迁移的索引mapping在新的es集群创建索引并设置mapping通过scroll不断获取数据并写入新索引，直到scroll获取的数据为空项目elasticsearch-migration","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://thare.cn/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://thare.cn/tags/Elasticsearch/"},{"name":"索引迁移","slug":"索引迁移","permalink":"https://thare.cn/tags/索引迁移/"}]},{"title":"ElasticSearch性能调优之设置refresh_interval实战","slug":"ElasticSearch性能调优之设置refresh_interval实战","date":"2018-09-28T07:36:51.000Z","updated":"2019-03-22T14:09:59.217Z","comments":true,"path":"posts/c358565.html","link":"","permalink":"https://thare.cn/posts/c358565.html","excerpt":"","text":"接手搜索几个月了，把公司的商品搜索从业务代码剥离成独立应用，再不断调整优化（代码结构），目前暂时趋于稳定（搜索中心化和产品化还有很长一段路要走），也能够迅速响应上层业务方的需求。自己也由一个搜索小白到了小试牛刀的阶段。项目中也还有很多可以改进的地方，自己对ES的深度和广度也有待加强。先贴上环境信息业务背景：商品ES版本：6.2.3集群配置：5台8核32G SSD系统信息：CentOS 7.2 64位索引信息：1100w个doc，5个分片，1个副本，约20G（不含副本）搜索应用的rt表现如下（qps约20）可以看到，请求主要分布在400ms以内，且有一条明显的100ms分界线。之前一直百思不得其解，直到某天看了@跳跳爸的Abc公众号的 中小规模搜索引擎（ElasticSearch）典型应用场景及性能优化（三）才恍然大悟：索引配置比较灵活，粒度也比较细，当我们查询索引时其实都是查询某个时间的一个快照数据，只有index searcher重载一次索引文件，这期间（两次reopen index searcher之间）对索引进行的操作才会可见，这段时间也叫做刷新时间（refresh_interval）需要注意的是重载索引文件（reopen index searcher）的开销很大，所以一般搜索引擎都是提供近实时的查询服务，以减少重载索引文件的次数，降低系统负载，有个案例：曾经将一个索引的刷新时间从1s调整到5s，整个搜索响应时间从200ms降低到20ms以内，效果可见一斑。高于100ms的请求应该是在es刷新时处理的，所以导致rt高。想象一下，每秒都要对1100w的索引重新刷新，这得多消耗性能。于是，尝试修改了该索引的refresh_interval为30s（商品搜索实时性没那么高）123456put /&#123;index&#125;/_settings&#123; \"index\": &#123; \"refresh_interval\": \"30s\" &#125;&#125;结果十分明显：可以看到，在16:05:30时刻将refresh_interval改成了30s，搜索应用的rt瞬间就下降了。并且可以看到，大概每隔30s会出现一两个请求rt较高的情况，这时候就是es重载了索引文件，导致请求变慢。这是调整后的日常rt，效果较之前已经好很多了，基本都在100ms以内不过还需继续努力，争取rt在50ms，并想办法消除refresh时的高rt。总结一下：ES的查询是近实时的（需要做好至少延迟1S的打算），实时性高的场景不适用；对于搜索结果实时性不高的场景（如上），可以适当增加refresh_internal，效果真的可见一斑。","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://thare.cn/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://thare.cn/tags/Elasticsearch/"},{"name":"性能调优","slug":"性能调优","permalink":"https://thare.cn/tags/性能调优/"}]},{"title":"Initialization","slug":"Initialization","date":"2018-09-27T13:07:52.000Z","updated":"2018-10-14T16:25:06.799Z","comments":true,"path":"posts/8b7d4dee.html","link":"","permalink":"https://thare.cn/posts/8b7d4dee.html","excerpt":"","text":"果然是懒癌患者，不过应该还没到晚期，还有得治。从大学起到研究生再到工作，中间多次下决心坚持写Blog，但最后往往都不了了之，其中最长坚持到一段时间应该是研究生期间了吧（献丑了）。当然也是知道对自己有帮助的，因为在写的过程中会总结思考，争取把技术和过程尽可能清楚地描述出来，这也是对自己做过和看过的一种总结。常言道，温故而知新。所以，今天打算重新拾起，打算利用写Blog这个过程好好总结工作中遇到的问题，并把这些记录下来，给未来的自己留个纪念，同时也希望能够帮助到其他人。","categories":[{"name":"随笔","slug":"随笔","permalink":"https://thare.cn/categories/随笔/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://thare.cn/tags/随笔/"}]}]}